{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Report on boosting<span class=\"tocSkip\"></span></h1>\n",
    "\n",
    "**High-dimensional statistics** lecture by [Anne GÃ©gout-Petit](http://www.iecl.univ-lorraine.fr/~Anne.Gegout/).\n",
    "\n",
    "Authors: [Sylvain Combettes](https://sylvaincom.github.io/) and [Lucas Lherbier](https://www.linkedin.com/in/lucas-lherbier/).\n",
    "\n",
    "Last update: Nov 24th, 2019.\n",
    "\n",
    "---\n",
    "This notebook completes our report on boosting. It contains a few implementations of the methods that were studied. In particular, we compare several classifiers on several datasets (for classication). All functions (except XGBoost) and datasets come from scikit-learn.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>README<span class=\"tocSkip\"></span></h4><p>\n",
    "The best way to open this Jupyter Notebook is to use the table of contents from the extensions called <code>nbextensions</code>. See <a href=\"https://towardsdatascience.com/4-awesome-tips-for-enhancing-jupyter-notebooks-4d8905f926c5\">4 Awesome Tips for Enhancing Jupyter Notebooks</a> by George Seif.\n",
    "    \n",
    "The Python version is 3.7.3.\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Defining-a-benchmarking-function-of-scores-and-processing-time-on-several-classifiers\" data-toc-modified-id=\"Defining-a-benchmarking-function-of-scores-and-processing-time-on-several-classifiers-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Defining a benchmarking function of scores and processing time on several classifiers</a></span></li><li><span><a href=\"#Launching-our-benchmark-on-several-simple-datasets-(for-classification)\" data-toc-modified-id=\"Launching-our-benchmark-on-several-simple-datasets-(for-classification)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Launching our benchmark on several simple datasets (for classification)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Iris-plants-dataset\" data-toc-modified-id=\"Iris-plants-dataset-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Iris plants dataset</a></span></li><li><span><a href=\"#Optical-recognition-of-handwritten-digits-dataset\" data-toc-modified-id=\"Optical-recognition-of-handwritten-digits-dataset-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Optical recognition of handwritten digits dataset</a></span></li><li><span><a href=\"#Wine-recognition-dataset\" data-toc-modified-id=\"Wine-recognition-dataset-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Wine recognition dataset</a></span></li><li><span><a href=\"#Breast-cancer-wisconsin-(diagnostic)-dataset\" data-toc-modified-id=\"Breast-cancer-wisconsin-(diagnostic)-dataset-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Breast cancer wisconsin (diagnostic) dataset</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Launching-our-benchmark-on-a-large-dataset-(for-classification)\" data-toc-modified-id=\"Launching-our-benchmark-on-a-large-dataset-(for-classification)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Launching our benchmark on a large dataset (for classification)</a></span></li><li><span><a href=\"#XGBoost-on-the-iris-dataset-(without-the-scikit-learn-API)\" data-toc-modified-id=\"XGBoost-on-the-iris-dataset-(without-the-scikit-learn-API)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>XGBoost on the iris dataset (without the scikit-learn API)</a></span></li><li><span><a href=\"#Further-work\" data-toc-modified-id=\"Further-work-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Further work</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports<span class=\"tocSkip\"></span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import process_time\n",
    "import datetime\n",
    "\n",
    "from sklearn import datasets, model_selection\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a benchmarking function of scores and processing time on several classifiers\n",
    "\n",
    "We are going to compare 4 classifiers from scikit-learn:\n",
    "- [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "- [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "\n",
    "and [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn) (a Python library on itself). However, XGBoost has a Python API for scikit-learn. For example, we can use scikit-learn's cross-validation on XGBoost.\n",
    "\n",
    "For each of the previous classifiers, we choose `n_estimators=50` and `max_depth=2` (when it applies). Thus, we do not tune the hyper-parameters.\n",
    "\n",
    "We are going to define a Python function that will return the benchmark of scores and processing time for each method. This function will be based on scikit-learn:\n",
    "- [Model selection and evaluation](https://scikit-learn.org/stable/model_selection.html)\n",
    "- [sklearn.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "\n",
    "We choose 10-fold cross validation.\n",
    "\n",
    "First, we define an intermediate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def score_and_time(model, X_dataset, y_dataset, cv):\n",
    "    \"\"\"\n",
    "    This function returns a list with the scores and processing times of model.\n",
    "    The scores are calculated with cross_val_score (with K-Fold equal to cv).\n",
    "    There are no hyper-parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    t_start = process_time()\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=cv)\n",
    "    t_stop = process_time()\n",
    "    part_l = [round(scores.mean(), 3), round(scores.std()*2, 3), datetime.timedelta(seconds=t_stop-t_start)]\n",
    "    \n",
    "    return part_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we define the benchmarking function itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def ml_benchmark(X_dataset, y_dataset, cv):\n",
    "    \"\"\"\n",
    "    This function returns a pandas dataframe with the scores and processing times of several classifiers\n",
    "        applied to X_dataset and y_dataset.\n",
    "    The scores are calculated with cross_val_score (with K-Fold equal to cv).\n",
    "    \"\"\"\n",
    "    \n",
    "    print('The shape of X_dataset is:', X_dataset.shape)\n",
    "    print('The shape of y_dataset is:', y_dataset.shape)\n",
    "    print('The set of values of y_dataset is:', set(y_dataset))\n",
    "     \n",
    "    rows_name = [\"DecisionTreeClassifier\", \"RandomForestClassifier\", \"AdaBoostClassifier\",\n",
    "                 \"GradientBoostingClassifier\", \"XGBoost\"]\n",
    "    \n",
    "    columns_name = ['Approx. mean of scores', 'Approx. variance of scores', 'Processing time']\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    l.append(score_and_time(model, X_dataset, y_dataset, cv))\n",
    "        \n",
    "    model = RandomForestClassifier(n_estimators=50, max_depth=2, random_state=0)\n",
    "    l.append(score_and_time(model, X_dataset, y_dataset, cv))\n",
    "    \n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=50, algorithm='SAMME',\n",
    "                               random_state=0)\n",
    "    l.append(score_and_time(model, X_dataset, y_dataset, cv))\n",
    "        \n",
    "    model= GradientBoostingClassifier(n_estimators=50, max_depth=2)\n",
    "    l.append(score_and_time(model, X_dataset, y_dataset, cv))\n",
    "    \n",
    "    model = xgb.XGBClassifier(n_estimators=50, max_depth=2, random_state=0)\n",
    "    l.append(score_and_time(model, X_dataset, y_dataset, cv))\n",
    "    \n",
    "    out = pd.DataFrame(l, index = rows_name, columns = columns_name)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching our benchmark on several simple datasets (for classification)\n",
    "\n",
    "We are going to launch our benchmark on several simple [datasets](https://scikit-learn.org/stable/datasets/index.html#toy-datasets) from scikit-learn. These datasets are all intented for classification (and not regression):\n",
    "- [Iris plants dataset](https://scikit-learn.org/stable/datasets/index.html#iris-plants-dataset)\n",
    "- [Optical recognition of handwritten digits dataset](https://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwritten-digits-dataset)\n",
    "- [Wine recognition dataset](https://scikit-learn.org/stable/datasets/index.html#wine-recognition-dataset)\n",
    "- [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-dataset)\n",
    "\n",
    "A description of these simple datasets is provided in the hyperlinks above.\n",
    "\n",
    "Indeed, scikit-learn comes with a few small standard datasets that do not require to download any file from some external website. These datasets are useful to quickly illustrate the behavior of the various algorithms implemented in scikit-learn. They are however often too small to be representative of real world machine learning tasks.\n",
    "\n",
    "## Iris plants dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is: (150, 4)\n",
      "The shape of y_dataset is: (150,)\n",
      "The set of values of y_dataset is: {0, 1, 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx. mean of scores</th>\n",
       "      <th>Approx. variance of scores</th>\n",
       "      <th>Processing time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.088</td>\n",
       "      <td>00:00:00.008216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.088</td>\n",
       "      <td>00:00:00.108430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.120</td>\n",
       "      <td>00:00:00.263899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.085</td>\n",
       "      <td>00:00:00.329929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.085</td>\n",
       "      <td>00:00:00.474944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Approx. mean of scores  \\\n",
       "DecisionTreeClassifier                       0.960   \n",
       "XGBoost                                      0.960   \n",
       "RandomForestClassifier                       0.953   \n",
       "AdaBoostClassifier                           0.953   \n",
       "GradientBoostingClassifier                   0.953   \n",
       "\n",
       "                            Approx. variance of scores Processing time  \n",
       "DecisionTreeClassifier                           0.088 00:00:00.008216  \n",
       "XGBoost                                          0.088 00:00:00.108430  \n",
       "RandomForestClassifier                           0.120 00:00:00.263899  \n",
       "AdaBoostClassifier                               0.085 00:00:00.329929  \n",
       "GradientBoostingClassifier                       0.085 00:00:00.474944  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_iris()\n",
    "X_dataset = dataset.data\n",
    "y_dataset = dataset.target\n",
    "\n",
    "df_benchmark_1 = ml_benchmark(X_dataset, y_dataset, 10)\n",
    "df_benchmark_1_sorted = df_benchmark_1.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "df_benchmark_1_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical recognition of handwritten digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is: (1797, 64)\n",
      "The shape of y_dataset is: (1797,)\n",
      "The set of values of y_dataset is: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx. mean of scores</th>\n",
       "      <th>Approx. variance of scores</th>\n",
       "      <th>Processing time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.072</td>\n",
       "      <td>00:00:12.257602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.061</td>\n",
       "      <td>00:00:07.209754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.059</td>\n",
       "      <td>00:00:02.023138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.077</td>\n",
       "      <td>00:00:00.161670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.103</td>\n",
       "      <td>00:00:00.485181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Approx. mean of scores  \\\n",
       "GradientBoostingClassifier                   0.913   \n",
       "XGBoost                                      0.910   \n",
       "AdaBoostClassifier                           0.855   \n",
       "DecisionTreeClassifier                       0.830   \n",
       "RandomForestClassifier                       0.791   \n",
       "\n",
       "                            Approx. variance of scores Processing time  \n",
       "GradientBoostingClassifier                       0.072 00:00:12.257602  \n",
       "XGBoost                                          0.061 00:00:07.209754  \n",
       "AdaBoostClassifier                               0.059 00:00:02.023138  \n",
       "DecisionTreeClassifier                           0.077 00:00:00.161670  \n",
       "RandomForestClassifier                           0.103 00:00:00.485181  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_digits()\n",
    "X_dataset = dataset.data\n",
    "y_dataset = dataset.target\n",
    "\n",
    "df_benchmark_2 = ml_benchmark(X_dataset, y_dataset, 10)\n",
    "df_benchmark_2_sorted = df_benchmark_2.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "df_benchmark_2_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine recognition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is: (178, 13)\n",
      "The shape of y_dataset is: (178,)\n",
      "The set of values of y_dataset is: {0, 1, 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx. mean of scores</th>\n",
       "      <th>Approx. variance of scores</th>\n",
       "      <th>Processing time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.072</td>\n",
       "      <td>00:00:00.282316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.075</td>\n",
       "      <td>00:00:00.442636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.157</td>\n",
       "      <td>00:00:00.608170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.100</td>\n",
       "      <td>00:00:00.194422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.144</td>\n",
       "      <td>00:00:00.011798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Approx. mean of scores  \\\n",
       "RandomForestClassifier                       0.973   \n",
       "AdaBoostClassifier                           0.972   \n",
       "GradientBoostingClassifier                   0.963   \n",
       "XGBoost                                      0.961   \n",
       "DecisionTreeClassifier                       0.895   \n",
       "\n",
       "                            Approx. variance of scores Processing time  \n",
       "RandomForestClassifier                           0.072 00:00:00.282316  \n",
       "AdaBoostClassifier                               0.075 00:00:00.442636  \n",
       "GradientBoostingClassifier                       0.157 00:00:00.608170  \n",
       "XGBoost                                          0.100 00:00:00.194422  \n",
       "DecisionTreeClassifier                           0.144 00:00:00.011798  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_wine()\n",
    "X_dataset = dataset.data\n",
    "y_dataset = dataset.target\n",
    "\n",
    "df_benchmark_3 = ml_benchmark(X_dataset, y_dataset, 10)\n",
    "df_benchmark_3_sorted = df_benchmark_3.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "df_benchmark_3_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer wisconsin (diagnostic) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is: (569, 30)\n",
      "The shape of y_dataset is: (569,)\n",
      "The set of values of y_dataset is: {0, 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx. mean of scores</th>\n",
       "      <th>Approx. variance of scores</th>\n",
       "      <th>Processing time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.035</td>\n",
       "      <td>00:00:01.516546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.057</td>\n",
       "      <td>00:00:00.356844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.056</td>\n",
       "      <td>00:00:00.451752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.070</td>\n",
       "      <td>00:00:00.383812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.065</td>\n",
       "      <td>00:00:00.062199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Approx. mean of scores  \\\n",
       "AdaBoostClassifier                           0.970   \n",
       "XGBoost                                      0.963   \n",
       "GradientBoostingClassifier                   0.960   \n",
       "RandomForestClassifier                       0.946   \n",
       "DecisionTreeClassifier                       0.918   \n",
       "\n",
       "                            Approx. variance of scores Processing time  \n",
       "AdaBoostClassifier                               0.035 00:00:01.516546  \n",
       "XGBoost                                          0.057 00:00:00.356844  \n",
       "GradientBoostingClassifier                       0.056 00:00:00.451752  \n",
       "RandomForestClassifier                           0.070 00:00:00.383812  \n",
       "DecisionTreeClassifier                           0.065 00:00:00.062199  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_breast_cancer()\n",
    "X_dataset = dataset.data\n",
    "y_dataset = dataset.target\n",
    "\n",
    "df_benchmark_4 = ml_benchmark(X_dataset, y_dataset, 10)\n",
    "df_benchmark_4_sorted = df_benchmark_4.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "df_benchmark_4_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the previous results, we can write the following ranking based on the mean of the scores on the four datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx. mean of scores</th>\n",
       "      <th>Approx. variance of scores</th>\n",
       "      <th>Processing time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.94850</td>\n",
       "      <td>0.07650</td>\n",
       "      <td>00:00:01.967362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.94725</td>\n",
       "      <td>0.09250</td>\n",
       "      <td>00:00:03.448117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.06350</td>\n",
       "      <td>00:00:01.078062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.91575</td>\n",
       "      <td>0.09125</td>\n",
       "      <td>00:00:00.353802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.90075</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>00:00:00.060970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Approx. mean of scores  \\\n",
       "XGBoost                                    0.94850   \n",
       "GradientBoostingClassifier                 0.94725   \n",
       "AdaBoostClassifier                         0.93750   \n",
       "RandomForestClassifier                     0.91575   \n",
       "DecisionTreeClassifier                     0.90075   \n",
       "\n",
       "                            Approx. variance of scores Processing time  \n",
       "XGBoost                                        0.07650 00:00:01.967362  \n",
       "GradientBoostingClassifier                     0.09250 00:00:03.448117  \n",
       "AdaBoostClassifier                             0.06350 00:00:01.078062  \n",
       "RandomForestClassifier                         0.09125 00:00:00.353802  \n",
       "DecisionTreeClassifier                         0.09350 00:00:00.060970  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark_total = (df_benchmark_1+df_benchmark_2+df_benchmark_3+df_benchmark_4) # we sum the four benchmarks\n",
    "df_benchmark_total = df_benchmark_total.divide(4) # we divide by the number of datasets to get the mean\n",
    "df_benchmark_total_sorted = df_benchmark_total.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "df_benchmark_total_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our ranking corresponds to what is commonly stated:\n",
    "1. XGBoost\n",
    "2. GradientBoostingClassifier\n",
    "3. AdaBoostClassifier\n",
    "4. RandomForestClassifier\n",
    "5. DecisionTreeClassifier\n",
    "\n",
    "In particular, `XGBoost` is much faster than `GradientBoostingClassifier`.\n",
    "\n",
    "Let us note that the datasets we used are too small to be representative of real world machine learning tasks: we can expect that the range of scores and processing time will increase. For example, with a larger dataset, we can expect `DecisionTreeClassifier` to perform much worse while `XGBoost` would perform not so badly: that it the case for the `digits` dataset that has more samples than the others. In the next section, we are going to address a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching our benchmark on a large dataset (for classification)\n",
    "\n",
    "We generate our classification dataset with scikit-learn's `make_classification` function.\n",
    "\n",
    "We try to be in the context of the _Statistics for high-dimensional data_ lecture by choosing `n_samples=500` and `n_features=1000` so that $n \\ll p$.\n",
    "\n",
    "More information can be found on scikit-learn's [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_classification(n_samples=500, n_features=1000, n_informative=20, n_classes=5,\n",
    "                              flip_y=0.001, class_sep=2, n_clusters_per_class=5, random_state=0)\n",
    "X_dataset = dataset[0]\n",
    "y_dataset = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is: (500, 1000)\n",
      "The shape of y_dataset is: (500,)\n",
      "The set of values of y_dataset is: {0, 1, 2, 3, 4}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx. mean of scores</th>\n",
       "      <th>Approx. variance of scores</th>\n",
       "      <th>Processing time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.128</td>\n",
       "      <td>00:00:36.693923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.112</td>\n",
       "      <td>00:00:44.510023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.416</td>\n",
       "      <td>0.086</td>\n",
       "      <td>00:00:35.098607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.352</td>\n",
       "      <td>0.151</td>\n",
       "      <td>00:00:00.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.317</td>\n",
       "      <td>0.151</td>\n",
       "      <td>00:00:02.128367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Approx. mean of scores  \\\n",
       "XGBoost                                      0.450   \n",
       "GradientBoostingClassifier                   0.417   \n",
       "AdaBoostClassifier                           0.416   \n",
       "RandomForestClassifier                       0.352   \n",
       "DecisionTreeClassifier                       0.317   \n",
       "\n",
       "                            Approx. variance of scores Processing time  \n",
       "XGBoost                                          0.128 00:00:36.693923  \n",
       "GradientBoostingClassifier                       0.112 00:00:44.510023  \n",
       "AdaBoostClassifier                               0.086 00:00:35.098607  \n",
       "RandomForestClassifier                           0.151 00:00:00.943000  \n",
       "DecisionTreeClassifier                           0.151 00:00:02.128367  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark_large = ml_benchmark(X_dataset, y_dataset, 10)\n",
    "df_benchmark_large_sorted = df_benchmark_large.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "df_benchmark_large_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the scores are bad but here we focus on comparing the models between them\n",
    "\n",
    "According to the previous results, we have the same ranking as before but the range in scores and processing time is higher on large datasets than smaller ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the small datasets, the score increased from DecisionTree to XGBoost by 5.3%.\n"
     ]
    }
   ],
   "source": [
    "scores = df_benchmark_total_sorted['Approx. mean of scores']\n",
    "perc_inc = round((scores[0]-scores[4])/(scores[4])*100, 2) # percentage increase of scores\n",
    "print('On the small datasets, the score increased from DecisionTree to XGBoost by {}%.'.format(perc_inc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the large dataset, the score increased from DecisionTree to XGBoost by 41.96%.\n"
     ]
    }
   ],
   "source": [
    "scores = df_benchmark_large_sorted['Approx. mean of scores']\n",
    "perc_inc = round((scores[0]-scores[4])/(scores[4])*100, 2) # percentage increase of scores\n",
    "print('On the large dataset, the score increased from DecisionTree to XGBoost by {}%.'.format(perc_inc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On large datasets (that are harder to predict), it is more obvious that `XGBoost` performs much better than `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost on the iris dataset (without the scikit-learn API)\n",
    "\n",
    "Unfortunately, XGBoost is not on scikit-learn, thus we apply it in a different section.\n",
    "The goal of this section is run XGBoost without using the scikit-learn API in order to understand the `DMatrix` format.\n",
    "We used the following tutorial: [A Beginnerâs guide to XGBoost](https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7).\n",
    "\n",
    "First of all, we load and prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for XGBoost to be able to use our data, weâll need to transform it into a specific format called `DMatrix` that XGBoost can handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our XGBoost model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 3}\n",
    "\n",
    "steps = 20  # The number of training iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train and we test our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9761904761904763\n",
      "Recall = 0.9444444444444445\n",
      "Accuracy = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(param, D_train, steps)\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further work\n",
    "\n",
    "The following scikit-learn tutorials are interesting to read:\n",
    "- [Classifier comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py)\n",
    "- [Discrete versus Real AdaBoost](https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_hastie_10_2.html#sphx-glr-auto-examples-ensemble-plot-adaboost-hastie-10-2-py)\n",
    "- [Two-class AdaBoost](https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_twoclass.html)\n",
    "- [Multi-class AdaBoosted Decision Trees](https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_multiclass.html)\n",
    "- [Plot the decision surfaces of ensembles of trees on the iris dataset](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_iris.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Back to [top](#top)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242.167px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
